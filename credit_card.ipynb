{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPoGHdcv94grF2AAeEq0FAm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SRIVARSHINI-J/CODSOFT/blob/main/credit_card.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUFBZanuClqP",
        "outputId": "43e84ac4-8b99-4acb-d06c-dd82c4c91fb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking for null values:\n",
            "Time      0\n",
            "V1        0\n",
            "V2        0\n",
            "V3        0\n",
            "V4        0\n",
            "V5        0\n",
            "V6        0\n",
            "V7        0\n",
            "V8        0\n",
            "V9        0\n",
            "V10       0\n",
            "V11       0\n",
            "V12       0\n",
            "V13       0\n",
            "V14       0\n",
            "V15       0\n",
            "V16       0\n",
            "V17       0\n",
            "V18       0\n",
            "V19       0\n",
            "V20       0\n",
            "V21       1\n",
            "V22       1\n",
            "V23       1\n",
            "V24       1\n",
            "V25       1\n",
            "V26       1\n",
            "V27       1\n",
            "V28       1\n",
            "Amount    1\n",
            "Class     1\n",
            "dtype: int64\n",
            "Confusion Matrix:\n",
            "[[4360    1]\n",
            " [   3   15]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00      4361\n",
            "         1.0       0.94      0.83      0.88        18\n",
            "\n",
            "    accuracy                           1.00      4379\n",
            "   macro avg       0.97      0.92      0.94      4379\n",
            "weighted avg       1.00      1.00      1.00      4379\n",
            "\n",
            "\n",
            "Accuracy Score:\n",
            "0.9990865494405116\n"
          ]
        }
      ],
      "source": [
        "#overall coding\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "# Loading the dataset\n",
        "data = pd.read_csv('credit (1).csv')\n",
        "\n",
        "# Checking for null values\n",
        "print(\"Checking for null values:\")\n",
        "print(data.isnull().sum())\n",
        "\n",
        "# Droping rows where y is NaN\n",
        "data = data.dropna(subset=['Class'])\n",
        "\n",
        "# Separate features and target\n",
        "X = data.drop(['Class', 'Time'], axis=1)\n",
        "y = data['Class']\n",
        "\n",
        "# Check for null values in features and drop them\n",
        "X = X.dropna()\n",
        "y = y.loc[X.index]  # Ensure y matches the indices of the cleaned X\n",
        "\n",
        "# Feature scaling for 'Amount'\n",
        "scaler = StandardScaler()\n",
        "X['Amount'] = scaler.fit_transform(X[['Amount']])\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "# Initialize the model\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"\\nAccuracy Score:\")\n",
        "print(accuracy_score(y_test, y_pred))\n"
      ]
    }
  ]
}